%----------------------------------------------------------------------------------------
%	SECTION 1.1
%----------------------------------------------------------------------------------------

\section{Taylor's Theorem.}

\begin{definition}
    If $f$ has a derivative  $f'$ on an interval, and  $f'$ is differentiable, we 
    denote $f''$ to be  $(f')'$ and call it the \textbf{second derivative} of $f$; likewise, 
    if $f''$ is differentiable, we denote the \textbf{third derivative} by  $f^{(3)}=(f'')'$. More 
    generally, for  $n \in \Z^+$, we define recursively the  \textbf{$n$th derivative} to be:
        \begin{enumerate}[label=(\arabic*)]
            \item $f^{(0)}=f$ and $f^{(1)}=f'$.

            \item $f^{(n+1)}=(f^{(n)})'$, given that $f^{(n)}$ is differentiable.
        \end{enumerate}
        We call $f$ \textbf{$n$th differentiable} if  $f^{(n)}$ exists.
\end{definition}

\begin{theorem}[Taylor's Theorem]\label{6.5.1}
    Suppose $f:[a,b] \rightarrow \R$ is a realvalued function, that is  $n$th differentiable, and let 
    $n \in \Z^+$ be such that $f^{(n-1)}$ is continuous on  $[a,b]$, and that  $f^{(n)}$ exists on 
    $(a,b)$. LEt  $\alpha, \beta \in [a,b]$ be distinct, and define:
        \begin{equation}
            p(t)=\sum_{k=0}^{n-1}{\frac{f^{(k)}(\alpha)}{k!}(t-\alpha)^k}		
        \end{equation}
        Then there exists a point $x \in (\alpha, \beta)$ such that $f(\beta)=p(\beta)+\frac{f^{(n)}(x)}{n!}(\beta-\alpha)^n$.
\end{theorem}
\begin{proof}
    For $n=1$, this reduces to the mean value theorem, so suppose that  $n>1$. Let $M \in \R$ be 
    such that $f(\beta)=p(\beta)+M(\beta-\alpha)^n$, and let  $g(t)=f(t)-p(t)+M(\beta-\alpha)^n$, for $t \in [a,b]$. 
    Then  $g$ is  $n$th differentiable, and  we get  $g^{(n)}=f^{(n)}-n!M$ for  $t \in (a,b)$. We 
    wish to show that $f^{(n)}=n!M$.

    We have that  $p^{(k)}=f^{(k)}(\alpha)$ for  $0 \leq k \leq n-1$, then  $g(\alpha)=g'(\alpha)= \dots = g^{(n-1)}(\alpha)=0$, 
    and our choice of  $M$ shows that  $g(\beta)=0$. So  $g'(x_1)=0$ for $x_1 \in (\alpha,\beta)$, so by 
    the mean value theorem, since $g'(\alpha)=0$, then  $g''(\x_2)=0$ for $x_2 \in (\alpha,x_2)$. Proceeding 
    inductively, we then get that $g_^{(n)}(x_n)=0$ for $x_n \in (\alpha,x_{n-1})$, hence we 
    get that $n!M=f^{(n)}(x)$.
\end{proof}

\begin{definition}		
    We call the series in equation $(5.2)$ the \textbf{Taylor series} (or \textbf{Taylor polynomial}) 
    of $f$ about  $\alpha$. We call the realnumber  $M$ such tat  $n!M=f^{(n)}(x)$ the 
    \textbf{tail},  (or \textbf{error}) of the Taylor series.
\end{definition}
