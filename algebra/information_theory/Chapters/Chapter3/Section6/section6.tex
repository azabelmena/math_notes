%----------------------------------------------------------------------------------------
%	SECTION 1.1
%----------------------------------------------------------------------------------------

\section{Coordinates.}
\label{section1}
 
We return to our discussion on vector spaces, specially concerning bases and row equivalence
(covered in next section). Here, we introduce the concept of a ``coordinate space''.

\begin{definition}
    If $V$ is a finite dimensional vector space, we define an  \textbf{ordered basis} of $V$ to be a
    finite sequence of vectors, which form a basis for  $V$.
\end{definition}

Let $\Bc=\{\alpha_1, \dots \alpha_n\}$ be an ordered basis of a vector space $V$ of $\dim{V}=n$.
Then there is a unique $n$-tuple of scalars such that  $\alpha=\sum_{i_1}^n${x_i\alpha_i}. W call
$x_i$ the  $i$-th  \textbf{coordinate} of $\alpha$  \textbf{relative} to $\Bc$.

Now let  $\beta=\sum{y_i\alpha_i}$ be another vector of $V$ and define  $+:V \times V \rightarrow V$
and  $\cdot"F \times V \rightarrow V$ by $\alpha+\beta=\sum{(x_i+y_i)\alpha_i}$ and
$c\alpha=\sum{(cx_i)\alpha_i}$. We see then that $\Bc$ determines a  $1-1$ mapping  $\alpha
\rightarrow (x_1, \dots, x_n)$ of $V$ onto  $F^n$.

\begin{definition}
    Let $V$ be a vector space of  $\dime{V}=n$, and $\Bc-\{\alpha_1, \dots, \alpha_n\}$ a coordinate
    basis. Let $\alpha=(x_1, \dots, x_n)$. We call the $n \times 1$ matrix
    \begin{equation}
        X=\begin{pmatrix}
            x_1 \\
            \vdots \\
            x_n
          \end{pmatrix}
    \end{equation}
    the \textbf{coordinate matrix} of $\alpha$  \textbf{relatve} to $\Bc$. We also write $X$ as
    $X=(x_1, \dots, x_n)^T$.
\end{definition}

\begin{theorem}\label{2.6.1}
    Let $V$ be an $n$-dimensional vector space over a field $F$. let $\Bc$ and  $\Bc'$ be ordered
    bases of  $V$. Then there is a unique $n \times n$ invertible matrix  $P$ over  $F$ such that:
     \begin{enumerate}
         \item[(1)] $(\alpha)_{\Bc}=P(\alpha)_{\Bc'}$.

         \item[(2)] $(\alpha)_{\Bc'}=P^{-1}(\alpha)_{\Bc}$.
    \end{enumerate}
    for all $\alpha \in V$. The columns of $P$ are $P_j=(\alpha'_j)_{\Bc}$.
\end{theorem}
\begin{proof}
    Let $\Bc=\{\alpha_1, \dots, \alpha_n\}$ and $\Bc'=\{\alpha'_1, \dots, \alpha'_n\}$. There are
    unique scalars $P_{ij} \in F$ such that $\alpha_j'=\sum_{i=1}^n{P_{ij}\alpha_i}$ for $1 \leq i
    \leq n$. Now let  $(x_1', \dots, x_n')$ be the coordinates of  $\alpha$ with respect to  $\Bc'$.
    Then
    $\alpha=\sum_{j=1}^n{x_j'\alpha_j'}=\sum{x_j}\sum{P_{ij}\alpha_i}=\sum{\sum{(P_{ij}x_j')\alpha_i}}$.
    Since $(x_1, \dots, x_n)$ are uniquely determined in $\Bc$, we get
    $x_i=\sum_{j=1}^n{P_{ij}x_j'}$ for $1 \leq i \leq n$.

    Now define the matrix  $P=(P_{ij})_{n \times n}$ and let $X=(x_1, \dots, x_n^T)$ and $X'=(x_1',
    \dots, x_n')^T$. Then we have $X=PX'$. Since  $\Bc$ and  $\Bc'$ are bases, and hence linearly
    independent, we get  $X=0$ if and only if  $X'=0$, so  $X'=P^{-1}X$ by row equivalence.
\end{proof}

\begin{theorem}\label{2.6.8}
    Suppose $P$ is an  $n \times n$ invertrible matrix over  $F$. let  $V$ ne an  $n$-dimensional
    vector space over  $F$ and let  $\Bc$ be an ordered basis of  $V$. Then there is a unique
    ordered basis  $\Bc'$ of  $V$ such that:\
     \begin{enumerate}
         \item[(1)] $(\alpha)_{\Bc}=P(\alpha)_{\Bc'}$.

         \item[(2)] $(\alpha)_{\Bc'}=P^{-1}(\alpha)_{\Bc}$.
    \end{enumerate}

    for all $\alpha \in V$.
\end{theorem}
\begin{proof}
    Let $\Bc=\{\alpha_1, \dots, \alpha_n\}$. if $\Bc'=\{\alpha_1', \dots, \alpha_n'\}$,
    then from the previous theorem, we get $\alpha_j'=\sum{P_{ij}\alpha_i}$. Notice
    then that
    $\sum_{j}{P_{ij}}=\sum_{j}{P^{-1}_{jk}}\sum_{i}{P_{ij}\alpha_i}=\sum_{i}{\sum_{j}{P_{ij}P^{-1}_{jk}}\alpha_i}=\alpha_k$;
    which spans $\Bc$, and hence  $V$. So   $\Bc'$ is a basis. That  $\Bc'$ is unique comes from
    linear independence.
\end{proof}

\begin{example}
    \begin{enumerate}
        \item[(1)] Let $F$ be an arbitrary field, and let  $\alpha=(x_1, \dots, x_n) \in F^n$. Let
            $\Bc=\{e_1, \dots, e_n\}$ be the standard basis of $F^n$.  $\Bc$ is an ordered basis,
            and we have  $\alpha=(x_1, \dots, x_n)^T$.

        \item[(2)] let $F=\R$ and  $\theta \in \R$. Consider the matrix
            $P=\begin{pmatrix}
                \cos{\theta} & -\sin{\theta} \\
                \sin{\theta} & \cos{\theta} \\
               \end{pmatrix}$. $P$ is invertible with 
               $P^{-1}=\begin{pmatrix}
                   \cos{\theta} & \sin{\theta} \\
                -\sin{\theta} & \cos{\theta} \\
            \end{pmatrix}$, so for all $\theta \in \R$, the subspace  $\Bc'=\{(\cos{\theta},
            \sin{\theta}), (-\sin{\theta}, \cos{\theta})\}$ is an ordered basis for $\R^2$. We
            visualize this basis by rotating the standard basis anticlockwise by an angle of
            $\theta$. Let $\alpha=(x_1,x_2)$, then:
                \begin{equation*}
                    (\alpha)_{\Bc'}=\begin{pmatrix}
                                \cos{\theta} & \sin{\theta} \\
                                -\sin{\theta} & \cos{\theta}
                               \end{pmatrix}
                               \begin{pmatrix}
                                x_1 \\
                                x_2 \\
                               \end{pmatrix}
                \end{equation*}
            which gives
                \begin{align*}
                    x_1'    &=  x_1\cos{\theta}+x_2\sin{\theta} \\
                    x_2'    &=  -x_1\sin{\theta}+\x_2\cos{\theta} \\
                \end{align*}

            \item[(3)] Let $F=\C$. Consider the matrix  $P=\begin{pmatrix}
                                                            -1 & 4 & 5 \\
                                                             0 & 2 & -3 \\
                                                             0 & 0 & 8
                                                       \end{pmatrix}$
            which has inverse $P=\begin{pmatrix}
                                    -1 & 4 & 5 \\
                                     0 & \frac{1}{2} & \frac{3}{16} \\
                                     0 & 0 & \frac{1}{8}
                                 \end{pmatrix}$. So the vectors form a basis $\Bc'=\{(-1, 4, 5), (0,
                                 2, -3), (0, 0, 8)\}$ and the coordinates  $(x_1', x_2', x_3')$ of
                                 $\Bc'$ are given by:
            \begin{equation*}
                \begin{pmatrix}
                    x_1' \\
                    x_2' \\
                    x_3' \\
                \end{pmatrix}=
                \begin{pmatrix}
                    -1 & 4 & 5 \\
                     0 & \frac{1}{2} & \frac{3}{16} \\
                     0 & 0 & \frac{1}{8} \\
                \end{pmatrix}
                \begin{pmatrix}
                    x_1 \\
                    x_2 \\
                    x_3 \\
                \end{pmatrix}
            \end{equation*}
    \end{enumerate}
\end{example} 
